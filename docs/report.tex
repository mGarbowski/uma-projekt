\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{csvsimple} % Csv tables
\usepackage{adjustbox}
\usepackage{hyperref}
\usepackage[polish]{babel}
\usepackage[T1]{fontenc}
\usepackage[margin=0.5in]{geometry}

\usepackage{subcaption}

\title{UMA - Projekt}
\author{Mikołaj Garbowski, Michał Pałasz}
\date{Semestr 2024Z}

\begin{document}

\maketitle

\section{Temat projektu}
Implementacja drzewa decyzyjnego, porównanie sposobu radzenia sobie z problemami wieloklasowymi,
czyli porównanie jakości wyników typowej implementacji ID3 z jakością wyników dwóch podejść:

1) tworzymy osobny model binarny dla każdej klasy (jedna klasa traktowana jako pozytywna, wszystkie pozostałe jako negatywne),
predykcja przez wybór klasy o maksymalnej wartości funkcji decyzyjnej (wymaga posiadania przez każdy klasyfikator
„stopnia pewności siebie”, co można zdefiniować na wiele sposobów).
2) tworzymy osobny model binarny dla każdej pary klas (jedna klasa traktowana jako pozytywna, druga jako negatywna),
predykcja przez głosowanie.

\section{Opis rozwiązania}

\subsection{Algorytm ID3}
Przy tworzeniu liścia, poza klasą większościową zapamiętujemy również częstość występowania przykładów klasy większościowej
w zbiorze przykładów rozważanym w danym liściu.
W przypadku jednakowej klasy dla wszystkich przykładów - wartość 1, w pozostałych przypadkach - wartość z przedziału $(0,1)$.
Częstość potraktujemy jako stopień pewności modelu co do decyzji.

\subsection{Wariant One vs Rest}
Dla problemu klasyfikacji z liczbą klas równą $n$ powstanie $n$ modeli klasyfikacji binarnej według algorytmu ID3.

Dla pojedynczego modelu dla klasy $c$, modyfikujemy etykiety w zbiorze danych - wszystkie etykiety klas innych niż $c$ zamieniamy na klasę negatywną, $c$ traktujemy jako klasę pozytywną.

Wynikiem predykcji zespołu modeli będzie ta klasa, którą model binarny zaklasyfikował pozytywnie z największą pewnością.

Przykładowo, dla klas A, B, C, D

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|c|c|c|}
\hline
Model binarny dla klasy & A & B & C & D \\ \hline
Predykcja (0/1)         & 1 & 0 & 1 & 0 \\
Pewność                 & 0,8 & 0,7 & 0,7 & 0,9 \\ \hline
\end{tabular}
\label{tab:ovr-example-1}
\end{table}

Predykcją zespołu modeli będzie klasa A, ponieważ zarówno model binarny dla klasy A i C dał pozytywny wynik klasyfikacji, ale model dla klasy A miał większą pewność.

Jeśli wszystkie modele binarne dadzą predykcję negatywną, predykcją zespołu modeli będzie ta klasa, która została zaklasyfikowana negatywnie z najmniejszą pewnością. Przykład:

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|c|c|c|}
\hline
Model binarny dla klasy & A & B & C & D \\ \hline
Predykcja (0/1)         & 0 & 0 & 0 & 0 \\
Pewność                 & 0,9 & 0,7 & 0,8 & 0,5 \\ \hline
\end{tabular}
\label{tab:binary-models}
\end{table}

Predykcją zespołu modeli będzie klasa D, ponieważ wszystkie predykcje dają klasę negatywną, ale model dla klasy D ma najmniejszą pewność

\subsection{Wariant One vs One}
Dla problemu klasyfikacji z liczbą klas równą $n$ powstanie $n(n-1)/2$ modeli klasyfikacji binarnej - po 1 dla każdej pary klas.
Klasyfikator binarny rozstrzyga do której klasy z pary należy przykład.

Do trenowania klasyfikatora binarnego dla pary klas A i B użyjemy takiego podzbioru zbioru trenującego, który zawiera tylko przykłady klas A i B.

Predykcja zespołu klasyfikatorów będzie wyznaczana przez głosowanie.
Ze względu na możliwość remisu przy zliczaniu głosów jako liczby modeli które przewidują daną klasę, proponujemy poniższy sposób obliczania głosów ważonych stopniem pewności predykcji
(stopień predykcji definiowany jak w poprzednim wariancie).

Przykład dla klas A, B i C:

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
Model binarny dla pary & A vs B & B vs C & C vs A \\ \hline
Predykcja              & A      & B      & C      \\
Pewność                & 0,99   & 0,8    & 0,7    \\ \hline
\end{tabular}
\label{tab:binary-pairs}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|}
\hline
Klasa & Ważony głos \\ \hline
A     & 1,29 = 0,99 + (1-0,7) \\
B     & 0,81 = (1-0,99) + 0,8 \\
C     & 0,9 = (1-0,8) + 0,7 \\ \hline
\end{tabular}
\label{tab:weighted-votes}
\end{table}

Dla powyższego przykładu predykcją zespołu klasyfikatorów byłaby klasa A, ponieważ choć wszystkie uzyskały po 1 głosie,
dla każdej klasy obliczamy sumę pewności głosów \textit{za} i dopełnienia do 1 pewności głosów \textit{przeciw}.

\section{Zbiory danych}


\subsection{\href{https://archive.ics.uci.edu/dataset/19/car+evaluation}{Car Evaluation}}



Celem zbioru jest klasyfikacja samochodów na podstawie ich cech, takich jak cena, koszty utrzymania czy pojemność pasażerska, do jednej z czterech kategorii akceptowalności

\begin{itemize}
    \item unacc
    \item acc
    \item good
    \item vgood
\end{itemize}

\subsubsection*{Charakterystyka zbioru danych:}
\\
\textbf{Liczba próbek:} 1728 \\
\textbf{Liczba cech:} 6 atrybutów wejściowych + 1 cecha docelowa \\
\textbf{Typy danych:} kategoryczne \\

\subsection{\href{https://archive.ics.uci.edu/dataset/12/balance+scale}{Balance Scale}}

Celem zbioru jest klasyfikacja stanu równowagi szalki wagi na podstawie masy i odległości obiektów umieszczonych na jej lewym i prawym ramieniu. Każda próbka jest przypisywana do jednej z trzech kategorii:
\begin{itemize}
    \item \texttt{L} (szalka przechylona w lewo),
    \item \texttt{B} (szalka w równowadze),
    \item \texttt{R} (szalka przechylona w prawo).
\end{itemize}

\subsubsection*{Charakterystyka zbioru danych:}

\begin{itemize}
    \item \textbf{Liczba próbek:} 625
    \item \textbf{Liczba cech:} 4 atrybuty wejściowe + 1 cecha docelowa
    \item \textbf{Typy danych:} kategoryczne
\end{itemize}

\subsection{\href{https://archive.ics.uci.edu/dataset/936/national+poll+on+healthy+aging+(npha)}{National Poll on Healthy Aging (NPHA)}}

Celem zbioru jest przewidywanie liczby odwiedzanych lekarzy przez Amerykanów powyżej 50 roku życia na podstawie odpowiedzi respondentów w ankiecie na temat ich zdrowia. Liczba lekarzy jest sprowadzona do 3 kategorii:
\begin{itemize}
    \item 1 - 0 lub 1
    \item 2 - 2 lub 3
    \item 3 - 4 lub więcej
\end{itemize}

\subsubsection*{Charakterystyka zbioru danych:}

\begin{itemize}
    \item \textbf{Liczba próbek:} 714
    \item \textbf{Liczba cech:} 14 atrybutów wejściowych + 1 cecha docelowa
    \item \textbf{Typy danych:} kategoryczne
\end{itemize}

Żaden z powyższych zestawów danych nie posiada brakujących danych.

\section{Macierze pomyłek}
Przykładowe macierze pomyłek dla wszystkich zbiorów danych i klasyfikatorów.
Prezentowane macierze pomyłek są otrzymane z jednokrotnego wykonania predykcji przy podejściu z oddzielnym zbiorem uczącym i testowym (podzielone w proporcji $0.6$).

\begin{figure}[ht]
    \centering
    \begin{tabular}{ccc}
        \begin{subfigure}{0.3\textwidth}
            \centering
            \csvautotabular{results/confusion-matrices/ID3_Balance-scale.csv}
            \caption{ID3: Balance Scale}
        \end{subfigure} &
        \begin{subfigure}{0.3\textwidth}
            \centering
            \csvautotabular{results/confusion-matrices/ID3_Car.csv}
            \caption{ID3: Car}
        \end{subfigure} &
        \begin{subfigure}{0.3\textwidth}
            \centering
            \csvautotabular{results/confusion-matrices/ID3_NPHA.csv}
            \caption{ID3: NPHA}
        \end{subfigure} \\
        \begin{subfigure}{0.3\textwidth}
            \centering
            \csvautotabular{results/confusion-matrices/One-Vs-One_Balance-scale.csv}
            \caption{One vs One: Balance Scale}
        \end{subfigure} &
        \begin{subfigure}{0.3\textwidth}
            \centering
            \csvautotabular{results/confusion-matrices/One-Vs-One_Car.csv}
            \caption{One vs One: Car}
        \end{subfigure} &
        \begin{subfigure}{0.3\textwidth}
            \centering
            \csvautotabular{results/confusion-matrices/One-Vs-One_NPHA.csv}
            \caption{One vs One: NPHA}
        \end{subfigure} \\
        \begin{subfigure}{0.3\textwidth}
            \centering
            \csvautotabular{results/confusion-matrices/One-Vs-Rest_Balance-scale.csv}
            \caption{One vs Rest: Balance Scale}
        \end{subfigure} &
        \begin{subfigure}{0.3\textwidth}
            \centering
            \csvautotabular{results/confusion-matrices/One-Vs-Rest_Car.csv}
            \caption{One vs Rest: Car}
        \end{subfigure} &
        \begin{subfigure}{0.3\textwidth}
            \centering
            \csvautotabular{results/confusion-matrices/One-Vs-Rest_NPHA.csv}
            \caption{One vs Rest: NPHA}
        \end{subfigure}
    \end{tabular}
    \caption{Macierze pomyłek}
    \label{fig:confusion-matrices-grid}
\end{figure}

\newpage
\section{Metryki}
Do porównania jakości klasyfikacji modeli wykorzystujemy metryki:
dokładność, odzysk, precyzja, miara F, specyficzność, TP rate, FP rate.

Dla zastosowania standardowych metryk klasyfikacji binarnej do problemu klasyfikacji wieloklasowej stosujemy
podejście makro-uśredniania i mikro-uśredniania. Wyniki dla obu wariantów przedstawiono w tabelach.

Dla każdej metryki podajemy wartość średnią i odchylenie standardowe wyliczone przy
k-krotnej walidacji krzyżowej z $k=5$.


\subsection{Makro-uśrednianie}
\begin{table}[h!]
    \centering
    \begin{adjustbox}{valign=c, width=\textwidth}
        \csvautotabular{results/metrics/macro-1.csv}
    \end{adjustbox}
    \label{tab:metrics-macro-1}
\end{table}

\begin{table}[h!]
    \centering
    \begin{adjustbox}{valign=c, width=\textwidth}
        \csvautotabular{results/metrics/macro-2.csv}
    \end{adjustbox}
    \label{tab:metrics-macro-2}
\end{table}

\subsection{Mikro-uśrednianie}

\begin{table}[h!]
    \centering
    \begin{adjustbox}{valign=c, width=\textwidth}
        \csvautotabular{results/metrics/micro-1.csv}
    \end{adjustbox}
    \label{tab:metrics-micro-1}
\end{table}

\begin{table}[h!]
    \centering
    \begin{adjustbox}{valign=c, width=\textwidth}
        \csvautotabular{results/metrics/micro-2.csv}
    \end{adjustbox}
    \label{tab:metrics-micro-2}
\end{table}

\section{Odstępstwa od dokumentacji wstępnej}

Uzupełnienie: przy obliczaniu miar jakości klasyfikacji stosujemy k-krotną walidację krzyżową z $k=5$ (średnie i odchylenia standardowe).

Zrezygnowaliśmy z wykreślania krzywych ROC i wyliczania AUC ze względu na problem ze zdefiniowaniem progu odcięcia dla rozważanych
modeli klasyfikacji.

Zbiór danych \textbf{nursery} zastąpiliśmy zbiorem \textbf{NPHA}, ponieważ wszystkie modele osiągały na nim dokładność zbliżoną do $100\%$

\end{document}
